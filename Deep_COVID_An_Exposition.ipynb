{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep COVID: An Exposition\n",
    "\n",
    "Throughout our report, we present the contents of 'Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning' (Deep-COVID, for short) by Minaee et al. We start with an introduction to the research question and overview of the data. Following this, we fit a logistic regression to the classification task. This will be used as our baseline model to compare the models used in the paper against. It also serves as an introduction to the basic concepts of Artificial Neural Networks (ANNs), as logistic regression can be viewed as a perceptron with sigmoid activation function. Using this as a segue, we, next, discuss the basic concepts involved in designing, and training ANN's. Once this is done, we introduce the concepts particular to Convolutional Neural Networks (CNNs). Then, we briefly discuss transfer learning and present the models used in the paper. Finally, we review their model evaluation metrics in comparison with eachother, our initial regression model, current biological-based tests, and discuss potential future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal of Deep-COVID and the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COVID pandemic represents one of the biggest challenges currently facing the United States and the rest of the world. Before vaccination is sufficiently deployed and adopted, efforts towards treatment and prevention are of much importance. One of the most effective tools we have at our disposal is accurate and speedy detection. Diagnosing cases from radiography and radiology image is, perhaps, one of the fastest forms of detection (Minaee et al., 2020). In their paper, Minaee et al. apply transfer learning to fit famous ANNs, including ResNet18, ResNet50, SqueezeNet, and DenseNet-121, to identify COVID-19 disease in analyzed chest X-ray images. Results were promising and it is the hope that these methods can be used to more accurately and quickly identify cases in exposed individuals. We'll discuss, in more detail, the concepts of transfer learning, as well as the basic concepts necessary to understand how the ANNs used are structured. First, however, let's become more acquainted with the data used for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of Deep-COVID were nice enough to share their data along with a description of how it was collected, labeled, and organized in a Github repository (https://github.com/shervinmin/DeepCovid/tree/master/data).  Still, we will give a brief synopsis in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used by the authors comes from two sources: \n",
    "* \"Covid-Chestxray-Dataset\", for COVID-positive samples\n",
    "* \"ChexPert Dataset\", for COVID-negative samples.\n",
    "\n",
    "<img src = \"Sample_images_visualization.jpg\" alt = \"Visualizations of Data\" style = \"width : 400px;\"/>\n",
    "\n",
    "From the Covid-Chestxray-Dataset, only images that were selected to have a clear sign of COVID by the authors' board-certified radiologists were used: a total of 71 images, split 31 for training and 40 for testing. Several data-augmentation techniques (as well as over-sampling) were used to increase the number of COVID-19 samples, leading to final training/test split counts of:\n",
    "\n",
    "<img src = \"Data_train_test_counts_table.jpg\" alt = \"Data_train_test_counts_table\" style = \"width : 500px;\"/>\n",
    "\n",
    "We note that one of the limitations of this project is the absence of a larger quantity of data, especially verified COVID-positive images. With the help of more data, we could hope for even better results. Now let's turn to our first model, a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: A Baseline Model and Segue into ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will fit a logitstic regression classifier to a subset of the author's data. This will serve two purposes. On the one hand, it will provide a baseline model to compare against the models used in Deep-COVID. And, on the other, it will serve as a segue into ANNs. Let us briefly recall the functional form of a logistic regression model. Namely, given a binary classification problem (say the two classes are 0 or 1) and a data point $\\mathbf{x}$, the probability that $\\mathbf{x}$ belongs to class 1 is given by:\n",
    "\n",
    "$$P(y_i = 1 | \\mathbf{x}) = \\frac{1}{1 + e ^ {-\\mathbf{w}^T \\mathbf{x}}}.$$\n",
    "\n",
    "This functional form can be thought of as the composition of two component functional forms. Namely, a linear component, $\\mathbf{z}_i = \\mathbf{w} ^ T \\mathbf{x} = w_1x_1 + ... + w_px_p$ and a non-linear component, $a_i = \\sigma(\\mathbf{a}_i)$, where $y_i = a_i$ and $\\sigma(x) = \\frac{1}{1 + e ^ {-x}}$ denotes a sigmoid function, which we will refer to as a sigmoid *activation* function. Thus, graphically, we can think of our model as follows:\n",
    "\n",
    "<img src = \"Single_Perceptron.png\" alt = \"Single Perceptron\" style = \"width : 500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train a model of this form to our classification task, we need to define how our input layer will look, i.e. what are our features. In the case of image classification tasks, it is common to use a matrix (2 dimensional for grey-scale images and 3 dimensional for color images) of pixel values of the images as the features. We can then take this matrix and \"flatten\" it, meaning that we convert it into a 1-Dimensional array (the form necessary for our intput layer above. Furthermore, we assign to each entry of the resulting vector, i.e. each pixel value a weight, and include it in the calculation of our linear component (\"Sum\" in the above graph). This means our model is \"fully connected\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the functional form of our model and it's architecture, let's discuss how we will train it using our training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 664 images belonging to 2 classes.\n",
      "Found 3100 images belonging to 2 classes.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 187500)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 187500)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 187501    \n",
      "=================================================================\n",
      "Total params: 187,501\n",
      "Trainable params: 187,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### Import the necessary modules #####\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "## Load in the training and testing images using ImageDataGenerator\n",
    "# Training images\n",
    "train_datagen = ImageDataGenerator(width_shift_range = 0.1)\n",
    "train_dir = 'C:/Users/Owner/Documents/STAT 6750/Project/data_upload_v2/train'\n",
    "\n",
    "train_covid_dir = 'C:/Users/Owner/Documents/STAT 6750/Project/data_upload_v2/train/covid'\n",
    "train_covid_names = os.listdir(train_covid_dir)\n",
    "\n",
    "train_non_dir = 'C:/Users/Owner/Documents/STAT 6750/Project/data_upload_v2/train/non'\n",
    "train_non_names = os.listdir(train_non_dir)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (250, 250),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "#Testing images\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_dir = 'C:/Users/Owner/Documents/STAT 6750/Project/data_upload_v2/test'\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (250, 250),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "## Define a logistic regression model as a perceptron with sigmoid activation function\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (250, 250, 3)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer = opt,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['binary_accuracy', 'TruePositives', 'TrueNegatives'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to ANNs and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Utilized in Minaee Et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Minaee, Shervin et al. “Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning.” Medical image analysis vol. 65 (2020): 101794. doi:10.1016/j.media.2020.101794\n",
    "\n",
    "2) Goodfellow, I., Bengio, Y., &amp; Courville, A. (2017). Deep learning. Cambridge, MA: MIT Press.\n",
    "\n",
    "3) Deshpande, M. (2020, September 29). Perceptrons: The First Neural Networks. Retrieved November 23, 2020, from https://pythonmachinelearning.pro/perceptrons-the-first-neural-networks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
